[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "metaSurvey",
    "section": "",
    "text": "Descripción del proyecto\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEste capítulo está en proceso de escritura. Consulte la rama de desarrollo para ver el avance del capítulo\n\n\n\n\n\nmetaSurvey",
    "crumbs": [
      "Descripción del proyecto"
    ]
  },
  {
    "objectID": "chapters/chapter1.html",
    "href": "chapters/chapter1.html",
    "title": "1  Introducción",
    "section": "",
    "text": "Nota\n\n\n\nEste capítulo está en proceso de validación. Cualquier comentario es bienvenido\n\n\n\nEl presente trabajo final de grado tiene como objetivo presentar el desarrollo del paquete metaSurvey disponible en R (R Core Team, 2023). R es un leguaje de programación de código abierto ampliamente utilizado en la comunidad científica para el análisis de datos, estadística y aprendizaje automático, y en general se utiliza el concepto paquete para referirse a una colección de funciones, métodos y clases que extienden las funcionalidades de R propuestas por la misma comunidad de usuarios. A lo largo de deste trabajo se abordarán varios conceptos clave tanto para el desarrollo del paquete como para el análisis de encuestas por muestreo.\nActualemente existen varios esfuerzos para facilitar el procesamiento de encuestas, entre ellos existen principalmente dos tipos de paquetes, aquellos que implementan la metodología de inferencia en muestreo de poblaciones finitas como puede ser el paquete survey (lumley2024?), gustave (Incluir cita), vardpoor, svrep, weights y aquellos que permiten acceder y manipular encuestas específicas como ech (Detomasi, 2020), eph (Kozlowski et al., 2020), tidycensus (Walker & Herman, 2024), casen (Incluir cita) entre otros. Sin embargo, estos ultimos tienen limitaciones en cuanto a la flexibilidad y transparencia del proceso de transformación de los microdatos a indicadores de interés, como puede ser el indice de pobreza, tasas del mercado laboral, ingreso salarial, etc. En general, sus implementaciones son muy sensibles a la estructura y las variables que componen la encuesta, un cambio en la estructura de la encuesta suele implicar una actualización del paquete utilizado para obtener los indicadores en la nueva edicición de la encuesta, lo que resulta poco flexible ante cambios en la estructura, que pueden ser frecuentes en la práctica. Además en las implementaciones actuales, el usuario cuenta con una función de alto nivel que actúa como una caja negra, donde no se permite modificar el código para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin tener que leer el código fuente o la documentación adjunta.\nEste tipo de problemas puede verse en ech (Detomasi, 2020), donde existen funciones para crear variables de mercado laboral, educación o ingresos, pero estas funciones dependen de la existencia de ciertas variables en la encuesta, cuya estructura puede cambiar de una versión a otra de la encuesta. Sin revisar el cuerpo de la función, no se conoce el proceso de construcción de variables. Algo similar ocurre con eph (Kozlowski et al., 2020), donde se tienen funciones de alto nivel que no permiten modificar el código para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin inspeccionar a fondo cómo se construyen las funciones del paquete. Esta inspección del código fuente, como consultar el repositorio de GitHub del paquete o revisar la definición de la función, puede ser una tarea tediosa y no garantiza que el usuario pueda entender el proceso de construcción de variables. Esto se debe a que el código puede ser muy extenso o que el usuario no tenga el conocimiento suficiente para entender el código o se empleen ciertos frameworks que el usuario no conozca, como el uso de las librerías dplyr (Wickham et al., 2023) o tidyr (Wickham et al., 2024), muy populares en R para el manejo de datos. También puede ser difícil aislar el proceso de manipulación de la encuesta de la implementación específica de la función para manejar la forma de presentación, estructura del objeto a devolver, etc. Un claro ejemplo de esto puede verse en tidycensus (Walker & Herman, 2024), donde existe una función para obtener datos sobre la migración de la comunidad estadounidense, pero en la misma función también se encuentran pasos para mejorar la estructura del conjunto de datos a devolver. En este sentido, el usuario no puede aislar el proceso de recodificación/construcción de variables sobre variables originales y la obtención de datos geográficos y presentación.\nPara cientificos sociales, es importante tener en cuenta que el proceso de transformación de los microdatos a indicadores requiere de un conocimiento profundo de la encuesta y en su mayoría no es de conocimiento general. Es de interés obtener información histórica de indicadores y en general es un proceso tedioso y propenso a errores, especialmente si proviene de encuestas donde su estructura y/o forma de preguntar o su codificación puede cambiar con el tiempo. Esto resulta en un proceso extenso y difícil de entender hasta llegar a la construcción de esta serie de indicadores. Muchas veces, diferentes usuarios hacen el mismo proceso de construcción de indicadores de manera independiente y sin compartir el código fuente o la metodología de construcción de indicadores, ya que cada uno utiliza su propio estilo de programación o hasta diferentes paquetes estadísticos, en su mayoría propietarios como SPSS, SAS o STATA, donde si bien el usuario puede compartir la sintaxis para su construcción, esta está ligada al software y depende de que el usuario tenga el software instalado con una licencia activa y pueda correr el código.\nEn este sentido, es importante que el usuario pueda tener un control total sobre el proceso de transformación de los microdatos a indicadores, ya que esto permite que el usuario pueda validar y entender el proceso de construcción de indicadores, además de brindar una herramienta común libre de estilos de programación y definiendo con simples pasos el proceso de construcción de variables sintéticas, como recodificar variables creando grupos en base a criterios complejos, tratamiento de variables continuas como el ingreso salarial en base a una metodología rigurosa y facil de referenciar en la implementación. Es crucial que este proceso sea transparente y entendible para el usuario. En capitulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete metaSurvey y su implementación de recetas para la construcción de indicadores mediante la meta-programación.\nAl trabajar con encuestas por muestreo, es importante tener en cuenta la forma en la que se obtuvierón los datos y su proceso generador para poder realizar inferencias sobre la población de interés. En general, obtener estimaciones puntuales de estadísticos de totales, promedios o proporciones es relativamente sencillo, pero puede ser que se reporte una estimación donde no exista un tamaño de muestra suficiente para obtener una estimación confiable y/o que la variabilidad de la estimación sea alta y no sea recomendable su uso. En este sentido, es importante que el usuario no experto tenga de forma nativa una forma de obtener estimaciones puntuales y sus errores asociados de manera sencilla. Es común utilizar estimaciones puntuales sin tener una medida de incertidumbre o aún peor incluir una estimación del error estándar sin tener en cuenta el diseño muestral correcto, lo que puede llevar a conclusiones erróneas sobre la variabilidad de la estimación. metaSurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de forma nativa y con estos resultados hacer recomendaciones sobre la utilidad y confianza de la estimación mediante coeficientes de variación, intervalos de confianza, tamaño de muestra efectivo, entre otros sin tener que ser un experto en metodología de estimación de varianzas y remuestreo. En capitulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete metaSurvey y su implementación de estimaciones puntuales y sus errores asociados.\nEl desarrollo de un paquete en R es un proceso que requiere contar con una idea bien formada y los medios para llevarla a cabo es por esto que es importante contar con una metodología de trabajo ordenada, heredada del desarrollo de software convencional ya que para la publicación y difusión del paquete se tiene que cumplir con ciertos estándares de calidad y documentación para que otros usuarios puedan utilizarlo. En este sentido, es importante tener en cuenta que el desarrollo de un paquete en R puede llevar tiempo y esfuerzo, a consecuencia de esto, en el documento se presentarán diferentes conceptos sobre metodología para el desarrollo de paquetes en R y se aboraran ejemplos con la implementación de metaSurvey.\nEn este sentido, metaSurvey pretende ser una herramienta relevante para el trabajo con encuestas en ciencias sociales, buscando solucionar las limitaciones anteriormente mencionadas. Todo el proceso de transformación de los microdatos a indicadores se realiza a través de una serie de funciones que permiten al usuario tener un control total y transparente sobre el proceso de transformación de los microdatos a indicadores. Además, metaSurvey permite que el usuario pueda realizar el proceso de transformación de los microdatos a indicadores de manera reproducible y transparente. El usuario puede compartir el código de una forma entendible, casi como un “recetario de cocina”. El procedimiento aplicado a los datos utilizados para obtener los indicadores se realiza mediante lo que denominamos steps y recipes, conformando así una especie de camino transparente para la construcción de indicadores. Esto permite compartir en forma visual un DAG (Directed Acyclic Graph) que permite visualizar el proceso de construcción de indicadores sin tener que abrir un script de R. En complemento al proceso de creación de variables, metaSurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de manera sencilla y brindar recomendaciones sobre la utilidad de la estimación en el caso de que se cuente con una variabilidad alta en la estimación, en base a recomendaciones a su coeficiente de variación o métricas similares.\nEl enfoque que permite la flexibilidad a la hora de construir los indicadores es la meta-programación. La meta-programación es un paradigma de programación que permite que un programa pueda modificar su estructura interna en tiempo de ejecución. En R, la meta-programación se realiza a través de las funciones eval, parse, substitute, do.call y quote, que permiten evaluar y parsear código de manera dinámica. En este sentido, metaSurvey utiliza la meta-programación para permitir que el usuario pueda modificar el código que se utiliza para transformar los microdatos a indicadores, teniendo funciones de alto nivel similares a las que se utilizan en el paquete recipes de la librería tidymodels (Kuhn et al., 2024).\nEn el siguiente capitulo se presentara un marco conceptual básico sobre el muestreo de poblaciones finitas, diferentes paradigmas de programación como puede ser la programación orientada a objetos, programación funcional y la meta-programación y como se utilizan en el desarrollo del paquete. Luego, se ahondara en antecedentes previos tanto en la parte de metodología de estimación de varianzas y paquetes e ideas similares donde se basa el desarrollo del paquete. Finalmente, se presentarán ejemplos de cómo utilizar el paquete metaSurvey para construir indicadores de mercado laboral a partir de los microdatos de la ECH y para mostrar su flexibilidad, se incluirá un ejemplo con la EPH.\n\n\n\n\nDetomasi, G. M. &. R. (2020). ech: Caja de herramientas para procesar la Encuesta Continua de Hogares. https://github.com/calcita/ech\n\n\nKozlowski, D., Tiscornia, P., Weksler, G., Rosati, G., & Shokida, N. (2020). eph: Argentina’s Permanent Household Survey Data and Manipulation Utilities. https://holatam.github.io/eph/\n\n\nKuhn, M., Wickham, H., & Hvitfeldt, E. (2024). recipes: Preprocessing and Feature Engineering Steps for Modeling. https://github.com/tidymodels/recipes\n\n\nR Core Team. (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nWalker, K., & Herman, M. (2024). tidycensus: Load US Census Boundary and Attribute Data as ’tidyverse’ and ’sf’-Ready Data Frames. https://walker-data.com/tidycensus/\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). dplyr: A Grammar of Data Manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Vaughan, D., & Girlich, M. (2024). tidyr: Tidy Messy Data. https://tidyr.tidyverse.org",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html",
    "href": "chapters/chapter2.html",
    "title": "2  Marco conceptual",
    "section": "",
    "text": "2.1 Inferencia en muestreo de poblaciones finitas\nComo fue mencionado anteriormente las encuestas por muestreo son la principal fuente de información para la construcción de indicdores sociodemográficos y economicos, en este sentido, es importante tener en cuenta un marco teórico para realizar inferencias. Es sumamente sencillo obtener estimaciones puntuales de estadísticos usuales aunque es importante considerar la variabilidad de los estimadores, tanto para poder realizar un proceso de inferencia completo así como también para poder cuantificar la confiabilidad de la estimación. A continuación, se definen los conceptos básicos de inferencia en muestreo de poblaciones finitas como son el diseño muestral, probabilidades de inclusión basadas en el diseño, estimadores de Horvitz-Thompson HT, ponderación, medidas de incertidumbre y errores estándar basados en (Särndal et al., 2003).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "href": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "title": "2  Marco conceptual",
    "section": "",
    "text": "2.1.1 Diseño muestral\nEl concepto de diseño muestral refiere al mecanismo mediante el cual se selecciona una muestra donde aquí se determinan propiedades estadísticas claves como puede ser la distribución en el muestreo, valores esperados y varianzas de estimadores poblacionales. En diseños sencillos es posible calcular esta función o encontrar una expresión análitica con facilidad mientras que en diseños mas complejos como pueden ser los multietapicos es necesario abordar el problema de otra forma y asumir ciertas hipoesis para poder construir probabilidades de inclusión tanto de primer órden como segundo órden.\nLa definición matematica se basa en que dado un universo \\(U\\) de \\(N\\) elementos (puede ser conocido o no) \\(\\{u_{1},u_{2}, \\cdots, u_{N}\\}\\) y se considera un conjunto de tamaño \\(n\\) de elementos de \\(U\\) que se denota como \\(s = \\{u_{1},u_{2}, \\cdots, u_{n}\\}\\) al cual comunmente denominamos muestra, el diseño muestral puede definirse de la siguiente forma:\n\\[\nPr(S = s) = p(s)\n\\]\nRealizando un poco de inspección en la definición anterior se puede observar que el diseño muestral es una función de probabilidad que asigna una probabilidad a cada subconjunto de \\(U\\) de tamaño \\(n\\). En este sentido, es posible definir diferentes tipos de diseño, entre ellos los mas comunes:.\n\nDiseño Aleatorio Simple (SI)\n\nEl diseño aleatorio simple es el diseño más sencillo y se define de la siguiente forma:\n\\[\np(s) = \\frac{1}{\\binom{N}{n}}\n\\]\nDonde \\(\\binom{N}{n}\\) es el número de subconjuntos posibles de \\(U\\) de tamaño \\(n\\).\n\nDiseño Bernoulli (BE)\n\nEl (BE) es un diseño sencillo que se utiliza cuando se desea seleccionar una muestra de un universo de tamaño \\(N\\) además de considerar una una probabilidad de inclusión \\(\\pi\\) para cada elemento de \\(U\\). Se define el diseño Bernoulli de la siguiente forma:\n\\[\np(s) = \\underbrace{\\pi \\times \\pi \\times \\cdots \\times \\pi}_{n_{s}} \\times \\underbrace{(1-\\pi) \\times (1-\\pi) \\times \\cdots \\times (1-\\pi)}_{N-n_{s}} = \\pi ^{n_{s}} (1-\\pi)^{N-n_{s}}\n\\]\nUna diferencia fundamental entre el diseño (BE) y el diseño SI es que en el BE el tamaño de muestra es aleatorio y su distribución es binomial, mientras que en el diseño SI el tamaño de muestra es fijo.\n\nDiseño Estratificado (ST)\n\nEl diseño estratificado es un diseño que se utiliza cuando se desea seleccionar una muestra de tamaño \\(n\\) de un universo de tamaño \\(N\\) donde además se quiere dividir el universo en \\(H\\) estratos \\(U_{1}, U_{2}, \\cdots, U_{H}\\). Dentro de cada estrato se selecciona una muestra de tamaño \\(n_{h}\\) y se define el diseño estratificado de la siguiente forma:\n\\[\np(s) = \\prod_{l=1}^{H} p(s_{H})\n\\]\nEn cada estrato se puede utilizar un diseño diferente pero en general se utiliza el diseño SI, mas conocido STSI (Stratified Simple Random Sampling). En este caso cada \\(p_{h}(s_{h})\\) es el diseño aleatorio simple en el estrato \\(h\\).\n\n\n2.1.2 Probabilidades de inclusión y estimador de Horvitz-Thompson\nUna vez definido el concepto de diseño muestral es posible definir la probabilidad de que un elemento de la población sea seleccionado en la muestra, esta probabilidad se conoce como probabilidad de inclusión y se define de la siguiente forma:\n\nProbabilidad de inclusión de primer orden\n\n\\[\n\\pi_{k} = Pr(u_{k} \\in s) = Pr(I_{k} = 1)\n\\]\nDonde \\(I_{k}\\) es una variable aleatoria que toma el valor de 1 si el elemento \\(u_{k}\\) es seleccionado en la muestra y 0 en caso contrario. Definir estas variables indicadoras son de utilizada para entender el comportamiento de los estimadores bajo el diseño muestral y nos permite definir los estimaodres en \\(U\\) y no en \\(S\\). Es claro que \\(I_{k} \\sim Bernoulli(\\pi_{k})\\) y \\(E(I_{k}) = Pr(I_{k}) = \\pi_{k}\\).\nEsta probabilidad es importante ya que es la la base para la construcción de estimadores insesgados y eficientes, en este sentido, es posible definir el estimador de Horvitz-Thompson (HT) para estimar un total \\(t = \\sum_{U} {t_{k}}\\) de la siguiente forma:\n\\[\n\\hat{t}_{y} = \\sum_{k=1}^{N} \\frac{y_{k}}{\\pi_{k}} \\times I_{k}\n\\]\nEste estimador es propuesto por Horvitz y Thompson en 1952 y es un estimador insesgado en el diseño, en el sentido de que \\(E(\\hat{t}_{y}) = t\\) y es eficiente en el sentido de que \\(Var(\\hat{t}_{y})\\) es el menor posible entre los estimadores insesgados. Este estimador es muy utilizado en la práctica y es la base para la construcción de otros estadísticos,como medias, proporciones, varianzas, entre otros. Para mas detalles sobre las propiedades de Horvitz-Thompson (HT) se puede consultar en (Särndal et al., 2003) y (Horvitz & Thompson, 1952).\n\n\n2.1.3 Ponderación basada en el diseño y estimadores más comunes\nEn general es utilizado el concepto de ponderador para realizar estimaciones de totales, medias, proporciones, varianzas, entre otros. En este sentido, es posible definir el ponderador inducido por el diseño muestral de la siguiente forma:\n\\[\nw_{k} = \\frac{1}{\\pi_{k}}\n\\]\nEste ponderador puede interpretarse como el número individuos que representra el individuo \\(k\\) en la población. Este valor es el que comunmente se publica junto a los microdatos y el estandar en los diferentes softwares para procesar encuestas. Junto al estimador de un total es posible definir el estimador de un promedio, proporción o razón en el contexto de la $-expansión.\n\nEstimador de un promedio\n\\[\n\\hat{\\bar{y}} = \\frac{\\sum_{k=1}^{N} w_{k} I_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}}\n\\]\nEste estimador puede ser utilizados en encuestas de hogares, donde se desea estimar el ingreso promedio de los hogares de una región de forma anual, o mensual.\n\n\nEstimador de una proporción\n\\[\n\\hat{p} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\hat{N}}\n\\]\nPuede ser de interés estimar la proporción de hogares que tienen acceso a internet en una región, en este caso se puede utilizar el estimador de proporción.\n\n\nEstimador de una razón\nSe quiere estimar la razón \\(R = \\frac{\\sum_{k=1}^{N} y_{k}}{\\sum_{k=1}^{N} z_{k}}\\). En este caso se puede definir el estimador de la razón de la siguiente forma:\n\\[\n\\hat{R} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k}z_{k}} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\hat{N}}\n\\]\nEl estimador de razón es utilizado para constuir variables de mercado de trabajo como la tasa de desempleo, tasa de ocupación, entre otros.\n\n\nInferencia sobre el tamaño de la población\nUna vez definidos los estimadores, podemos ver que los estimaodres de medias y proporciones son un caso particular del estimador de razón. Un detalle no menor es que asumimos \\(N\\) fijo pero desconocido, por esto al realizar proporciones se ajusta el total sobre un estimador del tamaño de la población:\n\\[\n\\hat{N} = \\sum_{k=1}^{N} I_{k}w_{k}\n\\]\nExisten diseños denominados auto-ponderados donde por definición \\(\\sum_{k=1}^{N} w_{k} = N\\), en este caso particular el estimador de medidas y proporciones es un caso parciular del estimador de total, ya que el estadístico puede definirse de la siguiente forma:\n\\[\n\\hat{\\bar{y}}_{s} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{N} = \\frac{1}{N} \\times \\sum_{k=1}^{N} I_{k} w_{k} y_{k} = a \\times \\hat{t}_{y}\n\\]\n\n\n\n2.1.4 Medidas de incertidumbre y errores estándar\nSe puede medir la variabilidad de los estimadores y calcular su varianza. Esto es útil para entender cuán confiables son estos estimadores. Veamos cómo se calcula la varianza de diferentes tipos de estimadores, como el total, promedio, proporción o razón.\n\n2.1.4.1 Momentos muestrales y estimadores de varianza\nPara un estadístico \\(\\theta\\), su varianza bajo un diseño muestral \\(p(s)\\) se define como:\n\\[\nV(\\hat{\\theta}) = E((\\theta - E(\\hat{\\theta}))^{2}) = \\sum_{s \\in S}{p(s)\\left(\\hat{\\theta}_{s} - E(\\hat{\\theta}_{s})\\right)}\n\\]\nLa forma de calcular la varianza depende del estimador \\(\\hat{\\theta}\\). Por ejemplo, para el estimador de varianza de un total, se utiliza la siguiente fórmula:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k} \\times y_{k} \\times w_{k})} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k} \\times y_{k} \\times w_{k}, I_{l} \\times y_{l} \\times w_{l})}}\n\\]\nDespués de simplificar, obtenemos:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k}) \\times w_{k} \\times y_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k}, I_{l}) \\times y_{k} \\times w_{k} \\times y_{l}  \\times w_{l} }}\n\\]\nDonde definimos las siguientes identidades para simplificar cálculos:\n\\[\nCov(I_{k}, I_{l}) = \\Delta_{kl} = \\pi_{kl} - \\pi_{k} \\times \\pi_{l}\n\\]\n\\[\n\\check{y}_{k} = y_{k} \\times w_{k}\n\\]\n\\[\n\\check{\\Delta}_{kl} = \\Delta_{kl} \\times \\frac{1}{\\pi_{kl}} = \\Delta_{kl} \\times w_{kl}\n\\]\nUna vez definida la varianza del estimador, necesitamos estimar su varianza. Para esto, utilizamos la técnica de \\(\\pi\\)-expansión. Después de algunas manipulaciones algebraicas, obtenemos la varianza del estimador:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{\\check{y}_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} } = \\sum_{U}{\\sum{\\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }}\n\\]\nPodemos verificar que este estimador de varianza es insesgado con la definiciones de \\(E(I_{k}I_{l})\\) y tomando esperanzas. Es decir, se verifica que \\(E(\\hat{V}(\\hat{t}_{y})) = V(\\hat{t}_{y})\\). Al ser un estimador insesgado, su eficiencia depende del diseño muestral y de la varianza de los ponderadores, es decir, de la varianza de las probabilidades de inclusión. En algunos casos es donde entra en juego dividir grupos heterogéneos en estratos o realizar muestreos en varias etapas.\nPara el caso de un estimador de un promedio, la varianza se define de la siguiente forma: \\[\nV(\\hat{\\bar{y}}) = \\frac{1}{N^{2}} \\times \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }\n\\]\nEsto es válido en el caso de contar con un tamaño de población conocido, en otro caso el estimador de la media no es un estimador lineal y para calcular su varianza deben optar por métodos de estimación de varianzas más complejos como el de linealización de Taylor.\nEs importante considerar que en esta sección se presenta un caso ideal donde la muestra es obtenida de un listado perfecto de la población objetivo denominado marco de muestreo. En la práctica, el marco de muestreo es imperfecto y se debe considerar la no respuesta, la cobertura y la falta de actualización del marco de muestreo. En general para la publicación de microdatos se publican ponderadores los ponderadores originales sometidos a un proceso de calibración que ajusta los ponderadores para que los totales de la muestra coincidan con los totales de la población en algunas variables de control y permita mejorar el sesgo de no respuesta. El objetivo principal es crear ponderadores calibrados lo mas cercano posible a los ponderadores originales, de forma que si los ponderadores originales son insesgados, los ponderadores calibrados seran proximos a ser insesgados.\nAdemás de contar con ponderadores calibrados para calcular varianzas de los estimaodres HT es necesario contar con las probabilidades de inclusión de segundo orden, donde dependiendo del diseño este puede ser imposibles de calcular o pueden existir probabilidades de inclusión de segundo orden que sean cero. Por esto es necesario contar con diferentes estrategias de estimación de varianzas como pueden ser el Método del Ultimo Conglomerado, el Método de Jackknife, el Método de Bootstrap, entre otros.\nEn resumen, para realizar estimaciones puntuales ya sean totales, medias, proporciones o razones simplemente debemos ponderar los datos con los estadísticos anteriormente mencionadas pero para realizar un proceso de inferencia completo se requiere calcular sus errores estándar, construir intervalos de confianza y/o poder medir estabilidad de nuestros resultados. En este sentido, es importante tener al alcance herramientas que permitan realizar este tipo de cálculos, ya que si bien en diferentes softwares estadísiticos junto a la estimación puntual se presentan los errores estándar pero por defecto se asumen diseños sencillos como por ejemplo, el diseño BE donde la probabilidad de inclusión de segundo orden es sencilla de calcular y unicamente es necesario las probabilidades de inclusión de primer orden para computar estimadores del error estándar, siendo un valor completamente erroneo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#desarrollo-de-paquetes-en-r",
    "href": "chapters/chapter2.html#desarrollo-de-paquetes-en-r",
    "title": "2  Marco conceptual",
    "section": "2.2 Desarrollo de paquetes en R",
    "text": "2.2 Desarrollo de paquetes en R\nR al ser un lenguaje de código abierto y además cuenta con una gran comunidad de usuarios, en diferentes áreas de investigación, ha permitido que se desarrollen una gran cantidad de paquetes que permiten realizar diferentes tareas de análisis de datos, visualización, modelado, entre otros. En este sentido, el desarrollo de paquetes en R es una tarea que se ha vuelto muy común entre los usuarios de R, ya que permite compartir código, documentación y datos de manera sencilla.\nPara casi cualquier disciplina científica o en la industria se puede encontrar una comunidad de usuarios que desarrollan paquetes en R, en este sentido, el desarrollo de paquetes en R es una tarea que se ha vuelto muy común entre los usuarios de R y es muy sencillo de realizar. A continuación, se presentan los conceptos básicos para el desarrollo de paquetes en R.\n\n2.2.1 ¿Por qué desarrollar un paquete en R?\nDesarrollar un paquete en R tiene varias ventajas, entre las cuales se pueden mencionar las siguientes:\n\nReutilización de código: Es importante tener en cuenta que existe una comunidad que hace cosas similares a las que uno hace, por lo que es posible que alguien ya haya escrito una función que uno necesita. Por lo tanto, siempre es buena buscar si existe algún paquete que ya tenga las funcionalidades que se requieren.\nCompartir código: La comunidad de R es muy activa y siempre está dispuesta a compartir código, por esta razón es que se mantienen en constante desarrollo de paquetes.\nColaboración: El trabajo colaborativo es esencial en el desarrollo de paquetes en R, ya que permite que diferentes personas puedan aportar con nuevas funcionalidades, correcciones de errores, entre otros.\n\n\n\n2.2.2 Elementos básicos de un paquete en R\nPara que nuestro conjunto de funciones, datos y documentación sea considerado un paquete en R, es necesario que cumpla con ciertos requisitos mínimos. A continuación, se presentan los componentes mínimos que debe tener un paquete en R para ser publicado en CRAN.\n\nDirectorio: Un paquete en R debe estar contenido en un directorio que contenga al menos los siguientes archivos y directorios:\n\nR/: Directorio que contiene los archivos con las funciones que se desean incluir en el paquete.\nman/: Directorio que contiene los archivos con la documentación de las funciones que se encuentran en el directorio R/. En general se utiliza Roxygen2 (Wickham et al., 2024) para generar la documentación de las funciones.\nDESCRIPTION: Archivo que contiene la descripción del paquete, incluyendo el nombre, versión, descripción, autor, entre otros.\nNAMESPACE: Archivo que contiene la información sobre las funciones que se exportan y las dependencias del paquete.\nLICENSE: Archivo que contiene la licencia bajo la cual se distribuye el paquete.\nREADME.md: Archivo que contiene información general sobre el paquete.\n\nDocumentación: La documentación de las funciones es un componente esencial de un paquete en R, ya que permite que los usuarios puedan entender el funcionamiento de las funciones que se encuentran en el paquete. La documentación de las funciones se realiza utilizando el sistema de documentación de R, que se basa en el uso de comentarios en el código fuente de las funciones.\nPruebas: Es importante que el paquete tenga pruebas que permitan verificar que las funciones se comportan de la manera esperada. Las pruebas se realizan utilizando el paquete testthat (Wickham, 2011) que permite realizar pruebas unitarias.\nControl de versiones: Es importante que el paquete tenga un sistema de control de versiones que permita llevar un registro de los cambios que se realizan en el paquete. El sistema de control de versiones más utilizado en la comunidad de R es git.\nLicencia: Es importante que el paquete tenga una licencia que permita a los usuarios utilizar, modificar y distribuir el paquete. La licencia más utilizada en la comunidad de R es la licencia MIT.\n\nEl proceso de subir un paquete a CRAN es un proceso que puede ser tedioso, ya que se deben cumplir con ciertos requisitos que son revisados por los mantenedores de CRAN, no es trivial y puede tomar tiempo, sin embargo, es un proceso que vale la pena ya que permite que el paquete sea utilizado por una gran cantidad de usuarios.\nEl proceso de chequeo fue automatizado con github actions, por lo que cada vez que se realiza un cambio en el repositorio, se ejecutan los chequeos de CRAN y se notifica si el paquete cumple con los requisitos para ser publicado en caso de que no cumpla con los requisitos se notifica el error y no puede ser incluido en la rama principal del repositorio hasta que se corrija el error.\nTodo el proceso y código fuente del paquete se encuentra disponible en el repositorio de github del paquete. En el caso que este interesado en colaborar con el desarrollo del paquete puede consultar la guía de contribución",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#paradigmas-de-programación-en-r",
    "href": "chapters/chapter2.html#paradigmas-de-programación-en-r",
    "title": "2  Marco conceptual",
    "section": "2.3 Paradigmas de programación en R",
    "text": "2.3 Paradigmas de programación en R\nR es un lenguaje de programación que permite realizar programación funcional y orientada a objetos, lo que permite que los usuarios puedan utilizar diferentes paradigmas de programación para resolver problemas. A continuación, se presentan los conceptos básicos de la programación funcional y orientada a objetos en R.\n\n2.3.1 Programación funcional\nLa programación funcional es un paradigma de programación que se basa en el uso de funciones para resolver problemas. En R, las funciones son objetos de primera clase, lo que significa que se pueden utilizar como argumentos de otras funciones, se pueden asignar a variables, entre otros (Wickham, 2019, pp. 204-281). A continuación, se presentan los conceptos básicos de la programación funcional en R.\n\nFunciones de orden superior: En R, las funciones de orden superior son funciones que toman como argumento una o más funciones y/o retornan una función. Un ejemplo de una función de orden superior en R es la función lapply que toma como argumento una lista y una función y retorna una lista con los resultados de aplicar la función a cada elemento de la lista.\nFunciones anónimas: En R, las funciones anónimas son funciones que no tienen nombre y se crean utilizando la función function. Un ejemplo de una función anónima en R es la función function(x) x^2 que toma como argumento x y retorna x^2.\nFunciones puras: En R, las funciones puras son funciones que no tienen efectos secundarios y retornan el mismo resultado para los mismos argumentos. Un ejemplo de una función pura en R es la función sqrt que toma como argumento un número y retorna la raíz cuadrada de ese número.\n\nEste paradigma de programación es muy útil para realizar análisis de datos, ya que permite que los usuarios puedan utilizar funciones para realizar operaciones sobre los datos de manera sencilla y eficiente, dentro de metaSurvey no existe una presencia fuerte de programación funcional, sin embargo, se utilizan algunas funciones de orden superior para realizar operaciones sobre los datos.\n\n\n2.3.2 Programación orientada a objetos\nLa programación orientada a objetos es un paradigma de programación que se basa en el uso de objetos para resolver problemas. En R, los objetos son instancias de clases que tienen atributos y métodos (Mailund, 2017; Wickham, 2019, pp. 285-370). A continuación, se presentan los conceptos básicos de la programación orientada a objetos en R.\n\nClases y objetos: En R, las clases son plantillas que definen la estructura y el comportamiento de los objetos y los objetos son instancias de clases. En R, las clases se definen utilizando la función setClass y los objetos se crean utilizando la función new.\nAtributos y métodos: En R, los atributos son variables que almacenan información sobre el estado de un objeto y los métodos son funciones que permiten modificar el estado de un objeto. En R, los atributos se definen utilizando la función setClass y los métodos se definen utilizando la función setMethod.\n\nDentro de metaSurvey se utiliza la programación orientada a objetos para definir las clases de los objetos que se utilizan para representar los datos de las encuestas mediante una creación de una clase especifica llamada Survey que permite además de almacenar los datos de la encuesta añadir atributos y métodos que permiten realizar operaciones sobre los datos de manera sencilla y eficiente.\nDe forma similar se modelan las clases Step, Recipe y Workflow elementos cruciales en el ecosistema de metaSurvey donde se definen los pasos de preprocesamiento, recetas de preprocesamiento y flujos de trabajo respectivamente. En este caso particular se utiliza el paquete R6 (Chang, 2022) que permite definir clases de manera sencilla y eficiente además de permitir la herencia de clases y la definición de métodos y atributos de manera sencilla.\n\n\n2.3.3 Meta-programación\nLa meta-programación es un paradigma de programación que se basa en el uso de código para manipular código (Thomas Mailund, 2017; Wickham, 2019, pp. 373-500) . En R, la meta-programación se realiza utilizando el sistema de metaprogramación de R que se basa en el uso de expresiones, llamadas y funciones. A continuación, se presentan los conceptos básicos de la meta-programación en R.\n\nExpresiones: En R, las expresiones son objetos que representan código y se crean utilizando la función quote. Un ejemplo de una expresión en R es la expresión quote(x + y) que representa el código x + y.\nLlamadas: En R, las llamadas son objetos que representan la aplicación de una función a sus argumentos y se crean utilizando la función call. Un ejemplo de una llamada en R es la llamada call(\"sum\", 1, 2, 3) que representa la aplicación de la función sum a los argumentos 1, 2 y 3.\nFunciones: En R, las funciones son objetos que representan código y se crean utilizando la función function. Un ejemplo de una función en R es la función function(x, y) x + y que representa el código x + y.\n\n\n\n\n\nChang, W. (2022). R6: Encapsulated Classes with Reference Semantics.\n\n\nHorvitz, D. G., & Thompson, D. J. (1952). A Generalization of Sampling Without Replacement From a Finite Universe. Journal of the American Statistical Association, 47(260), 663-685. https://doi.org/10.2307/2280784\n\n\nMailund, T. (2017). Advanced Object-Oriented Programming in R: Statistical Programming for Data Science, Analysis and Finance. SPRINGER.\n\n\nSärndal, C.-E., Swensson, B., & Wretman, J. (2003). Model Assisted Survey Sampling. Springer Science & Business Media.\n\n\nThomas Mailund. (2017). Metaprogramming in R (1.ª ed.). Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804\n\n\nWickham, H. (2011). testthat: Get Started with Testing. The R Journal, 3, 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf\n\n\nWickham, H. (2019). Advanced R, Second Edition. CRC Press.\n\n\nWickham, H., Danenberg, P., Csárdi, G., & Eugster, M. (2024). roxygen2: In-Line Documentation for R. https://roxygen2.r-lib.org/",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html",
    "href": "chapters/chapter3.html",
    "title": "3  Antecedentes",
    "section": "",
    "text": "Advertencia\n\n\n\nEste capítulo está en proceso de escritura. Consulte la rama de desarrollo para ver el avance del capítulo",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Antecedentes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html",
    "href": "chapters/chapter4.html",
    "title": "4  Metodología",
    "section": "",
    "text": "Advertencia\n\n\n\nEste capítulo está en proceso de escritura. Consulte la rama de desarrollo para ver el avance del capítulo",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html",
    "href": "chapters/chapter5.html",
    "title": "5  Resultados",
    "section": "",
    "text": "5.1 ECH\nlibrary(magrittr)\n\nmetaSurvey::set_engine(\"data.table\")\n\nEngine: data.table\n\nech_meta = metaSurvey::load_survey(\n  path = metaSurvey::load_survey_example(\"ech_2018.csv\"),\n  svy_type = \"ech\",\n  svy_edition = \"2018\",\n  svy_weight = \"pesoano\"\n)\n\nech_meta_steps = ech_meta %&gt;%\n  metaSurvey::step_recode(\n    \"pea\",\n    pobpcoac %in% 2:5 ~ 1,\n    .default = 0\n  ) %&gt;%\n  metaSurvey::step_recode(\n    \"pet\",\n    pobpcoac != 1 ~ 1,\n    .default = 0\n  ) %&gt;%\n  metaSurvey::step_recode(\n    \"po\",\n    pobpcoac == 2 ~ 1,\n    .default = 0\n  ) %&gt;%\n  metaSurvey::step_recode(\n    \"pd\",\n    pobpcoac %in% 3:5 ~ 1,\n    .default = 0\n  )\nmetaSurvey::view_graph(ech_meta_steps)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Resultados</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#eaii",
    "href": "chapters/chapter5.html#eaii",
    "title": "5  Resultados",
    "section": "5.2 EAII",
    "text": "5.2 EAII\n\nsvy_example = metaSurvey::load_survey(\n    svy_type = \"eaii\",\n    svy_edition = \"2019-2021\",\n    svy_weight = \"w_trans\",\n    input = metaSurvey::load_survey_example(\"2019-2021.csv\"),\n    dec = \",\"\n)\n\n# as.data.frame(svy_example)\n# as.tibble(svy_example)\n\nnew_svy = svy_example %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"realiza_innovacion\",\n        B1_1_1 == 1 ~ 1,\n        B1_2_1 == 1 ~ 1,\n        B1_3_1 == 1 ~ 1,\n        B1_4_1 == 1 ~ 1,\n        B1_5_1 == 1 ~ 1,\n        B1_6_1 == 1 ~ 1,\n        B1_7_1 == 1 ~ 1,\n        B1_8_1 == 1 ~ 1,\n        B1_9_1 == 1 ~ 1,\n        .default = 0\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"sector\",\n        data.table::between(Division, 10, 33) ~ \"Industria\",\n        data.table::between(Division, 34, 99) ~ \"Servicios\",\n        Division == \"C1\" ~ \"Industria\",\n        Division == \"C2\" ~ \"Servicios\",\n        Division == \"E1\" ~ \"Servicios\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"innovativa\",\n        E1_1_1 == 1 ~ 1,\n        E1_2_1 == 1 ~ 1,\n        .default = 0\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"tipo_actividad\",\n        B1_1_1 == 1 ~ \"I + D Interna\",\n        B1_2_1 == 1 ~ \"I + D Externa\",\n        B1_3_1 == 1 ~ \"Bienes de Capital\",\n        B1_4_1 == 1 ~ \"Software\",\n        B1_5_1 == 1 ~ \"Propiedad Intelectual\",\n        B1_6_1 == 1 ~ \"Ingeniería\",\n        B1_7_1 == 1 ~ \"Capacitación\",\n        B1_8_1 == 1 ~ \"Marketing\",\n        B1_9_1 == 1 ~ \"Gestión\",\n        .default = \"Otra\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"tipo_innovacion\",\n        E1_1_1 == 1 ~ \"Producto\",\n        E1_2_1 == 1 ~ \"Proceso\",\n        .default = \"Otra\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"cant_traba_tramo\",\n        data.table::between(IG_4_1_3, 0, 4) ~ \"1\",\n        data.table::between(IG_4_1_3, 5, 19) ~ \"2\",\n        data.table::between(IG_4_1_3, 20, 99) ~ \"3\",\n        IG_4_1_3 &gt; 99 ~ \"4\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"ingreso_vta_pesos\",\n        data.table::between(IG_5_1_1_3, 0, 9942787) ~ \"1\",\n        data.table::between(IG_5_1_1_3, 9942788, 49713934) ~ \"2\", # nolint\n        data.table::between(IG_5_1_1_3, 49713935, 372854507) ~ \"3\", # nolint\n        IG_5_1_1_3 &gt; 372854507 ~ \"4\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"tamanio\",\n        cant_traba_tramo == \"1\" & ingreso_vta_pesos == \"1\" ~ \"Pequenias\",\n        cant_traba_tramo == \"2\" & ingreso_vta_pesos == \"2\" ~ \"Pequenias\",\n        cant_traba_tramo == \"2\" & ingreso_vta_pesos == \"1\" ~ \"Pequenias\",\n        cant_traba_tramo == \"1\" & ingreso_vta_pesos == \"2\" ~ \"Pequenias\",\n        cant_traba_tramo == \"3\" & ingreso_vta_pesos == \"3\" ~ \"Medianas\",\n        cant_traba_tramo == \"3\" & ingreso_vta_pesos == \"2\" ~ \"Medianas\",\n        cant_traba_tramo == \"3\" & ingreso_vta_pesos == \"1\" ~ \"Medianas\",\n        cant_traba_tramo == \"1\" & ingreso_vta_pesos == \"3\" ~ \"Medianas\",\n        cant_traba_tramo == \"2\" & ingreso_vta_pesos == \"3\" ~ \"Medianas\",\n        cant_traba_tramo == \"4\" & ingreso_vta_pesos == \"4\" ~ \"Grandes\",\n        cant_traba_tramo == \"4\" & ingreso_vta_pesos == \"3\" ~ \"Grandes\",\n        cant_traba_tramo == \"4\" & ingreso_vta_pesos == \"2\" ~ \"Grandes\",\n        cant_traba_tramo == \"4\" & ingreso_vta_pesos == \"1\" ~ \"Grandes\",\n        cant_traba_tramo == \"1\" & ingreso_vta_pesos == \"4\" ~ \"Grandes\",\n        cant_traba_tramo == \"2\" & ingreso_vta_pesos == \"4\" ~ \"Grandes\",\n        cant_traba_tramo == \"3\" & ingreso_vta_pesos == \"4\" ~ \"Grandes\"\n    ) %&gt;%\n    metaSurvey::step_compute(\n        subsector = Division\n    )\n\nmetaSurvey::get_metadata(new_svy)\n\nℹ️  Type: eaii\n📈 Edition: 2019-2021\n🖥️  Engine: data.table\n🧮 Weight: w_trans\n🔍 Steps: \n  - New group: realiza_innovacion\n  - New group: sector\n  - New group: innovativa\n  - New group: tipo_actividad\n  - New group: tipo_innovacion\n  - New group: cant_traba_tramo\n  - New group: ingreso_vta_pesos\n  - New group: tamanio\n  - New variable: subsector\n\n\n\nmetaSurvey::view_graph(new_svy)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Resultados</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#eph",
    "href": "chapters/chapter5.html#eph",
    "title": "5  Resultados",
    "section": "5.3 EPH",
    "text": "5.3 EPH\n\nph2022_3 = metaSurvey::load_survey(\n  path = metaSurvey::load_survey_example(\"eph2022_3.csv\"),\n  svy_type = \"eph\",\n  svy_edition = \"2022_3\",\n  svy_weight = \"PONDERA\"\n) %&gt;% \n  metaSurvey::step_recode(\n    \"pea\",\n    ESTADO %in% 1:2 ~ 1,\n    .default = 0\n  ) %&gt;% \n  metaSurvey::step_recode(\n    \"pet\",\n    ESTADO != 4 ~ 1,\n    .default = 0\n  ) %&gt;% \n  metaSurvey::step_recode(\n    \"po\",\n    ESTADO == 1 ~ 1,\n    .default = 0\n  ) %&gt;% \n  metaSurvey::step_recode(\n    \"pd\",\n    ESTADO == 2 ~ 1,\n    .default = 0\n  )\n\n\nmetaSurvey::view_graph(ph2022_3)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Resultados</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html",
    "href": "chapters/chapter6.html",
    "title": "6  Infraestructura",
    "section": "",
    "text": "Infra\nDocker\nKubernetes\nTests\nEnvío a CRAN\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEste capítulo está en proceso de escritura. Consulte la rama de desarrollo para ver el avance del capítulo",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Infraestructura</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7.html",
    "href": "chapters/chapter7.html",
    "title": "7  Resultados",
    "section": "",
    "text": "Advertencia\n\n\n\nEste capítulo está en proceso de escritura. Consulte la rama de desarrollo para ver el avance del capítulo",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Resultados</span>"
    ]
  }
]